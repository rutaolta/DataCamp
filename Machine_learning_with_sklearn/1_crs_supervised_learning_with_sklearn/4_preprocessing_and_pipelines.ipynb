{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e9bd79",
   "metadata": {},
   "source": [
    "Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b6fd1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbd2bf",
   "metadata": {},
   "source": [
    "Regression with categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d83aed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis=1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7a65b",
   "metadata": {},
   "source": [
    "Dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e41d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbbb36",
   "metadata": {},
   "source": [
    "Pipeline for song genre prediction: I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3884f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ec537",
   "metadata": {},
   "source": [
    "Pipeline for song genre prediction: II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac85f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abab217",
   "metadata": {},
   "source": [
    "Centering and scaling for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3f84f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f74d2",
   "metadata": {},
   "source": [
    "Centering and scaling for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239950a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0597346",
   "metadata": {},
   "source": [
    "Visualizing regression model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cc194",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726f2f8",
   "metadata": {},
   "source": [
    "Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb796e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import root_mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e02826",
   "metadata": {},
   "source": [
    "Visualizing classification model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248b538",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc81eb",
   "metadata": {},
   "source": [
    "Pipeline for predicting song popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0894e85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
